// src/dataLoader.js

import JSZip from "jszip";
import { XMLParser } from "fast-xml-parser";

/**
 * Normalize Arabic text by:
 *  - Removing all diacritics (tashkeel + kashida)
 *  - Unifying alef variants (Ø£Ø¥Ø¢ â†’ Ø§)
 *  - Converting final-Ù‰ â†’ ÙŠ, Ø© â†’ Ù‡, hamzas to base
 *  - Stripping any non-Arabic characters
 */
export function normalizeArabic(str = "") {
  return str
    .normalize("NFC")
    .replace(/[\u0610-\u061A\u064B-\u065F\u06D6-\u06ED\u0640]/g, "")
    .replace(/[Ø¥Ø£Ø¢]/g, "Ø§")
    .replace(/Ù‰/g, "ÙŠ")
    .replace(/Ø©/g, "Ù‡")
    .replace(/Ø¤/g, "Ùˆ")
    .replace(/Ø¦/g, "ÙŠ")
    .replace(/[^Ø¡-ÙŠ]/g, "");
}

// Buckwalter â†’ Arabic map (QAC v0.4)
const BW2AR = {
  "'": "Ø¡", "|": "Ø¢", ">": "Ø£", "&": "Ø¤", "<": "Ø¥", "}": "Ø¦",
  A: "Ø§", b: "Ø¨", p: "Ø©", t: "Øª", v: "Ø«", j: "Ø¬",
  H: "Ø­", x: "Ø®", d: "Ø¯", "": "Ø°", r: "Ø±", z: "Ø²",
  s: "Ø³", $: "Ø´", S: "Øµ", D: "Ø¶", T: "Ø·", Z: "Ø¸",
  E: "Ø¹", g: "Øº", f: "Ù", q: "Ù‚", k: "Ùƒ", l: "Ù„",
  m: "Ù…", n: "Ù†", h: "Ù‡", w: "Ùˆ", Y: "Ù‰", y: "ÙŠ",
  F: "Ù‹", N: "ÙŒ", K: "Ù", a: "ÙŽ", u: "Ù", i: "Ù",
  "~": "Ù’", o: "Ù‘", "`": "Ù°"
};
function buckwalterToArabic(bw) {
  return bw.split("").map(ch => BW2AR[ch] || ch).join("");
}

async function fetchQACText() {
  const res = await fetch("/qac.txt");
  if (!res.ok) throw new Error(`QAC fetch failed: ${res.status}`);
  let txt = await res.text();
  // Remove BOM so headers (# or LOCATION) are detected
  return txt.replace(/^\uFEFF/, "");
}

async function fetchNemlarZip() {
  const res = await fetch("/nemlar.zip");
  if (!res.ok) throw new Error(`Nemlar fetch failed: ${res.status}`);
  return res.blob();
}

/**
 * Parse QAC v0.4 into { entries, rootIndex }
 * - Strips out the header line (LOCATION	TOKEN	TAG	FEATURES)
 * - Skips any entry whose normalized token is empty
 */
function parseQAC(text) {
  const lines = text.split(/\r?\n/);
  const entries = [];
  const rootIndex = {};

  // Log first few non-header lines for your inspection
  const samples = lines
    .filter(l => l.trim() && !l.startsWith("#") && !l.startsWith("LOCATION\t"))
    .slice(0, 5);
  console.log("â–¶ï¸Ž sample QAC lines:", samples);

  lines.forEach((ln, idx) => {
    if (!ln.trim() || ln.startsWith("#")) return;
    if (ln.startsWith("LOCATION\tFORM\tTAG\tFEATURES")) return;

    const parts = ln.split("\t");
    if (parts.length !== 4) {
      console.log(`parseQAC skip line ${idx + 1}: ${parts.length} cols`);
      return;
    }

    const [location, bwForm, , feats] = parts;
    const token = buckwalterToArabic(bwForm);
    const featParts = feats.split("|");

    let prefix = "", stem = "", suffix = "", root = "", pattern = "", lemma = "", pos = "";

    featParts.forEach((f, i) => {
      if (f === "PREFIX")
        prefix = buckwalterToArabic((featParts[i + 1] || "").replace(/\+$/, ""));
      if (f === "SUFFIX")
        suffix = buckwalterToArabic((featParts[i + 1] || "").replace(/\+$/, ""));
      if (f.startsWith("ROOT:")) root = buckwalterToArabic(f.split(":")[1] || "");
      if (f.startsWith("PAT:") || f.startsWith("PATTERN:"))
        pattern = f.split(":")[1] || "";
      if (f.startsWith("LEM:")) lemma = buckwalterToArabic(f.split(":")[1] || "");
      if (f.startsWith("POS:")) pos = f.split(":")[1] || "";
    });

    stem = token;
    if (prefix && stem.startsWith(prefix)) stem = stem.slice(prefix.length);
    if (suffix && stem.endsWith(suffix))
      stem = stem.slice(0, stem.length - suffix.length);

    const normToken = normalizeArabic(token);
    const normRoot = normalizeArabic(root);
    if (!normToken) return;

    entries.push({
      location, token, prefix, stem, suffix,
      root, pattern, lemma, pos, normToken, normRoot
    });

    if (normRoot) {
      rootIndex[normRoot] = rootIndex[normRoot] || new Set();
      rootIndex[normRoot].add(location);
    }
  });

  Object.keys(rootIndex).forEach(r => {
    rootIndex[r] = Array.from(rootIndex[r]).sort();
  });

  console.log("parseQAC: total entries after filter:", entries.length);
  return { entries, rootIndex };
}

/**
 * Parse Nemlar ZIP (XML and/or JSON) into flat array of entries
 * Each entry has a `normToken` for matching
 */
async function parseNemlar(blob) {
  const zip = await JSZip.loadAsync(blob);

  const filenames = Object.keys(zip.files);
  console.log("ðŸ” nemlar.zip contains:", filenames);

  // group attrs in a.$, text in a._text
  const parser = new XMLParser({
    ignoreAttributes: false,
    attributeNamePrefix: "",
    attributesGroupName: "$",
    textNodeName: "_text"
  });

  const entries = [];

  await Promise.all(
    filenames.map(async (fname) => {
      const file = zip.files[fname];
      if (!file || !/\.(xml|json)$/i.test(fname)) return;

      const text = await file.async("string");

      if (fname.toLowerCase().endsWith(".xml")) {
        const json = parser.parse(text);
        const sents = json.FILE?.sentence ?? [];
        const list = Array.isArray(sents) ? sents : [sents];

        list.forEach(sent => {
          const anns = Array.isArray(sent.annotation)
            ? sent.annotation
            : [sent.annotation];
          anns.forEach(a => {
            const token = a._text || "";
            const normToken = normalizeArabic(token);
            if (!normToken) return;
            entries.push({
              filename: fname,
              sentenceId: sent.$?.id || "",
              token,
              prefix: a.$.prefix,
              stem: a.$.stem,
              suffix: a.$.suffix,
              root: a.$.root,
              pattern: a.$.pattern,
              lemma: a.$.lemma,
              pos: a.$.pos,
              normToken
            });
          });
        });

      } else {
        let docs;
        try {
          docs = JSON.parse(text);
        } catch {
          console.log(`parseNemlar: invalid JSON in ${fname}`);
          return;
        }
        const arr = Array.isArray(docs) ? docs : [];
        arr.forEach(doc => {
          const id = doc.id || doc.sentenceId || "";
          (doc.tokens || []).forEach(t => {
            const token = t.token || "";
            const normToken = normalizeArabic(token);
            if (!normToken) return;
            entries.push({
              filename: fname,
              sentenceId: id,
              token,
              prefix: t.prefix,
              stem: t.stem,
              suffix: t.suffix,
              root: t.root,
              pattern: t.pattern,
              lemma: t.lemma,
              pos: t.pos,
              normToken
            });
          });
        });
      }
    })
  );

  console.log("parseNemlar: total entries after filter:", entries.length);
  return entries;
}

// Public API

export async function loadQAC() {
  const txt = await fetchQACText();
  return parseQAC(txt);
}

export async function loadNemlar() {
  const blob = await fetchNemlarZip();
  return parseNemlar(blob);
}

export async function loadCorpora() {
  const [qacData, nemData] = await Promise.all([loadQAC(), loadNemlar()]);
  return { ...qacData, nemlarEntries: nemData };
}
